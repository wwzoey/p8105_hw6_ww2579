---
title: "p8105_hw6_ww2579"
author: "Wenzhao Wu"
date: "11/24/2020"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
library(p8105.datasets)

set.seed(1)

knitr::opts_chunk$set(
  fig.width = 12,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

```{r}
homicide_df = 
  read_csv("data/homicide_data.csv", na = c("", "NA", "Unknown")) %>% 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) %>% 
  filter(
    victim_race %in% c("White", "Black"),
    city_state != "Tulsa, AL") %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```

Start with one city.

```{r}
baltimore_df = 
  homicide_df %>%
  filter(city_state == "Baltimore, MD")

glm(resolution ~ victim_age + victim_sex + victim_race, data = baltimore_df,family = binomial()) %>%
  broom::tidy() %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)) %>%
  select(term, OR, starts_with(("CI"))) %>%
  knitr::kable(digits = 3)
```

Try this across cities.

```{r}
models_results_df = 
  homicide_df %>%
  nest(data = -city_state) %>%
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
    results = map(models, broom::tidy)) %>%
  select(city_state, results) %>%
  unnest(results) %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)) %>%
  select(city_state, term, OR, starts_with(("CI")))
```

Make a plot of city_state vs OR.

```{r}
models_results_df %>%
  filter(term == "victim_sexMale") %>%
  mutate(city_state = fct_reorder(city_state, OR)) %>%
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) +
  theme(axis.title.x = element_text(angle = 90, hjust = 1))
```

# Problem 2

Import and tidy the raw data.

```{r}
bwt_df = read.csv("./data/birthweight.csv") %>%
  mutate(babysex = as.factor(babysex),
         frace = as.factor(frace),
         malform = as.factor(malform),
         mrace = as.factor(mrace),
         parity = as.factor(parity)) %>%
  mutate(babysex = recode(babysex, "1" = "male", "2" = "female"),
         mrace = recode(mrace, "1" = "White", "2" = "Black", "3" = "Asian", "4" = "Puerto Rican", "8" = "Other"))

```


Fit a regression model for birthweight.

```{r}
# Full model
fit_bwt = lm(bwt~babysex + bhead + blength + delwt + fincome + frace + gaweeks + malform + menarche + mheight + momage + mrace + parity + pnumlbw + pnumsga + ppbmi + ppwt + smoken + wtgain, data = bwt_df)

# 10 predictors model
multi10_fit = lm(bwt~babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + ppwt + smoken, data = bwt_df)

# 6-predictor model
multi6_fit = lm(bwt~babysex + bhead + blength + delwt + gaweeks + mrace, data = bwt_df)

# 4-predictor model
multi4_fit = lm(bwt~babysex + bhead + blength + wtgain, data = bwt_df)

# Look at adjusted r^2 and AIC
broom::glance(fit_bwt)
broom::glance(multi10_fit)
broom::glance(multi6_fit)
broom::glance(multi4_fit)
```

First, I fitted all variables in a MLR model, and select variables of interest to build different models. Based on the summary of regression models, I compare the adjusted r^2 to check the goodness of fit. Among the 4 models above, the model with 10 predictors has the largest value of the adjusted r^2. Then I applied the criterion-based procedures to check for AIC to obtain a relatively "good" model. As a result, the 10-predictor model has the smallest AIC value. 

Selected predictors: babysex, bhead, blength, delwt, fincome, gaweeks, mheight, mrace, ppwt, smoken. 

Plot model residuals vs fitted values.

```{r}
new_df = bwt_df %>%
  add_predictions(multi10_fit) %>%
  add_residuals(multi10_fit)

resid_pred_plt = 
  new_df %>%
  ggplot(aes(x = pred, y = resid,color = babysex)) +
  geom_point() +
  geom_smooth(method = "lm", se = F)

resid_pred_plt
```

**Interpretation:**

As it is shown on the graph, most of the residuals bounce around 0, but the variance seems not quite constant and outliers are observed on the upper left.


The second fitted model:

```{r}
fit2 = lm(bwt~blength + gaweeks, data = bwt_df)
summary(fit2)
```

The third fitted model:

```{r}
fit3 = lm(bwt~babysex*bhead*blength, data = bwt_df)
summary(fit3)
```

**Comments:**

Based on regression analysis of two models, the model with a 3-way interaction seems fit better than the two-predictor model. The larger r^2 value implies a better "goodness of fit". From the results of fit3, the 3-way interaction of sex, head circumference and length at birth is statistically significant; while there seems no interaction effect between the head circumference and baby's length at birth.

Compare 3 models above using cross validation.

```{r}
cv_df = crossv_mc(bwt_df,100)
cv_df =
  cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

    
cv_df = 
  cv_df %>% 
  mutate(  
    fit1 = map(train, ~lm(data = .x, bwt~babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + ppwt + smoken)), 
    fit2 = map(train, ~lm(bwt~blength + gaweeks, data = .x)),
    fit3 = map(train, ~lm(bwt~babysex*bhead*blength, data = .x))) %>% 
  mutate(rmse_fit1 = map2(fit1, test, ~rmse(model = .x, data = .y)), 
         rmse_fit2 = map2(fit2, test, ~rmse(model = .x, data = .y)),
         rmse_fit3 = map2(fit3, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>%
  unnest(rmse) %>%
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
  labs(
    title = "Prediction Error Distributions")
```

**Comments:**

Fit1 is the model that I built by variable selection. Fit2 uses length at birth and gestational age as predictors. Fit3 is the one contains 3-way interaction term.
The graph of "Prediction Error Distributions" is used to compared predictive performance of different models. RMSE is computed for measurements. Based on what is shown on the graph, the first fitted model (i.e. 10-predictor model) has the lowest value of RMSE, thus has the best predictive performance among the three models. The second one, however, has the least predictive accuracy.


# Problem 3

Import and tidy and weather_df.

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


Bootstrapping

```{r}
set.seed(1)
bootstrap_df = weather_df %>%
  modelr::bootstrap(n = 5000) %>%
  mutate(models = map(strap, ~lm(tmax~tmin, data = .x)),
         r_squared = map(models, broom::glance),
         estimates = map(models, broom::tidy)) %>%
  unnest(r_squared,estimates)

log_df = bootstrap_df %>%
  select(term, estimate, r.squared) %>%
  pivot_wider(names_from = term,
              values_from = estimate,
              values_fn = list) %>%
  unnest(cols = c(`(Intercept)`, tmin)) %>%
  rename("beta0" = '(Intercept)', "beta1" = tmin) %>%
  mutate(log_estimates = log(beta0*beta1))
  

```

Plot distributions of estimates

```{r}
plot_r_squared = 
  log_df %>%
  ggplot(aes(x = r.squared)) +
  geom_density() + 
  labs(title = "r^2 Distribution")
plot_r_squared

plot_beta = 
  log_df %>%
  ggplot(aes(x = log_estimates)) +
  geom_density() +
  labs(title = "log_estimates Distribution")
plot_beta
```

**Comments:**

The distribution of r^2 seems to have a mean of 0.91, which is a quite high coefficient of determination, indicating on average, the model fits well on data. It can also be observed that there is a longer tail on the left side of the curve, which may be related to the frequency with which large outliers are included in bootstrap samples.

The distribution of log product of beta0 and beta1 is approximately normal, with a mean of 2.01.

Compute 95% CI for r^2

```{r}
lower_r2 = mean(log_df$r.squared) - qnorm(0.975) * sd(log_df$r.squared)
upper_r2 = mean(log_df$r.squared) + qnorm(0.975) * sd(log_df$r.squared)
```

Compute 95% CI for log product of beta0 and beta1

```{r}
lower_log = mean(log_df$log_estimates) - qnorm(0.975) * sd(log_df$log_estimates)
upper_log = mean(log_df$log_estimates) + qnorm(0.975) * sd(log_df$log_estimates)
```

**Interpretation:**

We are 95% confident that the r^2 will fall in somewhere between 0.895 and 0.928 for the regression analysis of tmax vs tmin. 

We are 95% confident that the log product of beta0 and beta1 will fall in somewhere between 1.966 and 2.060 for the regression analysis of tmax vs tmin. 